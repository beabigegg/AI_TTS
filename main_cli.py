# scripts/main_cli.py (ä¿®æ­£ tqdm å°å…¥å•é¡Œ)
import subprocess
import os
from pathlib import Path
import shutil
import json
import sys
import select
import pandas as pd # <--- æ–°å¢/ç§»è‡³æ­¤è™•
from tqdm import tqdm # <--- æ–°å¢

# --- åŸºæœ¬è¨­å®š ---
PROJECT_ROOT = Path(__file__).resolve().parent.parent
SCRIPTS_DIR = PROJECT_ROOT / "scripts"

VENV_PYTHON_CANDIDATES = [
    PROJECT_ROOT / ".venv" / "bin" / "python", # Linux/macOS
    PROJECT_ROOT / ".venv" / "Scripts" / "python.exe", # Windows
]
VENV_PYTHON = None
for path_candidate in VENV_PYTHON_CANDIDATES:
    if path_candidate.exists():
        VENV_PYTHON = path_candidate
        break
if VENV_PYTHON is None:
    print(f"è­¦å‘Šï¼šåœ¨é æœŸè·¯å¾‘ä¸­æ‰¾ä¸åˆ°è™›æ“¬ç’°å¢ƒçš„ Pythonã€‚å°‡å˜—è©¦ä½¿ç”¨ç³»çµ±é è¨­ 'python'ã€‚")
    print(f"è«‹ç¢ºä¿ 'python' æŒ‡å‘æ‚¨å°ˆæ¡ˆçš„è™›æ“¬ç’°å¢ƒï¼Œå¦å‰‡å¯èƒ½ç™¼ç”Ÿå¥—ä»¶ç‰ˆæœ¬å•é¡Œã€‚")
    PYTHON_EXECUTABLE = "python"
else:
    PYTHON_EXECUTABLE = str(VENV_PYTHON)
    print(f"åµæ¸¬åˆ°è™›æ“¬ç’°å¢ƒ Python: {PYTHON_EXECUTABLE}")

DATA_DIR = PROJECT_ROOT / "data"
RAW_SOURCES_BASE_DIR = DATA_DIR / "sources_raw"
DENOISED_SOURCES_BASE_DIR = DATA_DIR / "sources_denoised"
VAD_SEGMENTS_BASE_DIR = DATA_DIR / "processed" / "vad_segments"
RAW_TRANSCRIPTS_BASE_DIR = DATA_DIR / "processed" / "raw_transcripts"
TEMP_SEGMENTS_BASE_DIR = DATA_DIR / "processed" / "temp_segments_noisy"
FINAL_TRAINING_DATA_BASE_DIR = DATA_DIR / "processed" / "training_datasets"

DEFAULT_TRAIN_CONFIG_PATH = PROJECT_ROOT / "configs" / "base_config.json"
DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR = PROJECT_ROOT / "outputs" / "models"
DEFAULT_SYNTHESIS_OUTPUT_BASE_DIR = PROJECT_ROOT / "outputs" / "synthesis_results"
DEFAULT_CHAT_TEMP_AUDIO_DIR = PROJECT_ROOT / "outputs" / "temp_chat_audio"

# --- Helper Function ---
def run_command(command_parts, suppress_output=False, working_dir=None):
    """åŸ·è¡Œä¸€å€‹å‘½ä»¤åˆ—æŒ‡ä»¤ä¸¦å³æ™‚ä¸²æµå…¶è¼¸å‡º"""
    command_str = ' '.join(map(str, command_parts))
    effective_working_dir = working_dir if working_dir else PROJECT_ROOT
    print(f"\nâ–¶ï¸ æ­£åœ¨åŸ·è¡Œ (æ–¼ {effective_working_dir}): {command_str}")

    env = os.environ.copy()
    env['PYTHONPATH'] = str(PROJECT_ROOT) + os.pathsep + env.get('PYTHONPATH', '')
    env['PYTHONUNBUFFERED'] = "1"

    process = subprocess.Popen(
        command_parts, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
        text=True, encoding='utf-8', bufsize=1, universal_newlines=True,
        env=env, cwd=effective_working_dir
    )
    full_stdout, full_stderr = [], []
    if os.name != 'nt':
        while True:
            reads = [process.stdout.fileno(), process.stderr.fileno()]
            try:
                ret = select.select(reads, [], [])
                for fd in ret[0]:
                    if fd == process.stdout.fileno():
                        line = process.stdout.readline()
                        if line:
                            sys.stdout.write(line)
                            full_stdout.append(line)
                    if fd == process.stderr.fileno():
                        line = process.stderr.readline()
                        if line:
                            sys.stderr.write(line)
                            full_stderr.append(line)
            except ValueError:
                break
            if process.poll() is not None:
                break
    else:
        for stdout_line in iter(process.stdout.readline, ""):
            if stdout_line:
                sys.stdout.write(stdout_line)
                full_stdout.append(stdout_line)
        for stderr_line in iter(process.stderr.readline, ""):
            if stderr_line:
                sys.stderr.write(stderr_line)
                full_stderr.append(stderr_line)

    process.stdout.close()
    process.stderr.close()
    return_code = process.wait()

    if return_code == 0:
        if not suppress_output:
            print(f"âœ… æŒ‡ä»¤æˆåŠŸå®Œæˆ (è¿”å›ç¢¼ {return_code})")
        return True, "".join(full_stdout), "".join(full_stderr)
    else:
        print(f"âŒ æŒ‡ä»¤åŸ·è¡Œå¤±æ•— (è¿”å›ç¢¼ {return_code})")
        return False, "".join(full_stdout), "".join(full_stderr)

def get_user_input(prompt, default=None, is_path=False, ensure_exists=False, is_dir=False, check_empty=True):
    while True:
        if default is not None:
            response = input(f"{prompt} (é è¨­: {default}): ").strip()
            response = response if response else default
        else:
            response = input(f"{prompt}: ").strip()
        if check_empty and not response:
            print("è¼¸å…¥ä¸èƒ½ç‚ºç©ºï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
            continue
        if is_path:
            path_obj = Path(response)
            if ensure_exists:
                if not path_obj.exists():
                    print(f"éŒ¯èª¤ï¼šè·¯å¾‘ '{path_obj}' ä¸å­˜åœ¨ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
                    continue
                if is_dir and not path_obj.is_dir():
                    print(f"éŒ¯èª¤ï¼šè·¯å¾‘ '{path_obj}' ä¸æ˜¯ä¸€å€‹æœ‰æ•ˆçš„ç›®éŒ„ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
                    continue
            return path_obj
        return response

def ensure_directories():
    dirs_to_create = [
        RAW_SOURCES_BASE_DIR, DENOISED_SOURCES_BASE_DIR,
        VAD_SEGMENTS_BASE_DIR, RAW_TRANSCRIPTS_BASE_DIR,
        TEMP_SEGMENTS_BASE_DIR, FINAL_TRAINING_DATA_BASE_DIR,
        DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR, DEFAULT_SYNTHESIS_OUTPUT_BASE_DIR,
        DEFAULT_CHAT_TEMP_AUDIO_DIR, PROJECT_ROOT / "configs"
    ]
    for d_path in dirs_to_create:
        d_path.mkdir(parents=True, exist_ok=True)
    print("é è¨­ç›®éŒ„çµæ§‹å·²æª¢æŸ¥/å»ºç«‹ã€‚")


# --- å„å€‹æµç¨‹çš„å‡½å¼ ---
def step_download_audio():
    print("\n--- æ­¥é©Ÿ [dl]: ä¸‹è¼‰ YouTube éŸ³è¨Š ---")
    yt_url = get_user_input("è«‹è¼¸å…¥ YouTube URL (å½±ç‰‡æˆ–æ’­æ”¾åˆ—è¡¨)", check_empty=True)
    series_name = get_user_input("è«‹ç‚ºæ­¤éŸ³è¨Šç³»åˆ—å‘½å (ä¾‹å¦‚ MySinger_AlbumX)", check_empty=True)
    cmd = [
        PYTHON_EXECUTABLE, str(SCRIPTS_DIR / "download_audio.py"),
        yt_url, "--series_name", series_name, "--output_base_dir", str(RAW_SOURCES_BASE_DIR)
    ]
    success, _, _ = run_command(cmd)
    return RAW_SOURCES_BASE_DIR / series_name if success else None

def step_denoise_long_audio(input_series_dir_name: str = None):
    print("\n--- æ­¥é©Ÿ [dnl]: (å¯é¸) å°åŸå§‹é•·éŸ³è¨Šé€²è¡Œé™å™ª ---")
    if not input_series_dir_name:
        input_series_dir_name = get_user_input(f"è«‹è¼¸å…¥ä½æ–¼ '{RAW_SOURCES_BASE_DIR}' ä¸‹çš„åŸå§‹éŸ³è¨Šç³»åˆ—ç›®éŒ„å", check_empty=True)
    raw_audio_dir = RAW_SOURCES_BASE_DIR / input_series_dir_name
    if not raw_audio_dir.exists() or not raw_audio_dir.is_dir():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åŸå§‹éŸ³è¨Šç›®éŒ„ {raw_audio_dir}")
        return None
    denoised_output_dir = DENOISED_SOURCES_BASE_DIR / input_series_dir_name
    cmd = [
        PYTHON_EXECUTABLE, str(SCRIPTS_DIR / "denoise_audio_final.py"), # å‡è¨­æ‚¨çš„é™å™ªè…³æœ¬åç‚º denoise_audio_final.py
        "--input_dir", str(raw_audio_dir), "--output_dir", str(denoised_output_dir)
    ]
    success, _, _ = run_command(cmd)
    return denoised_output_dir if success else None

def step_vad_segmentation(input_series_dir_name: str = None, use_denoised: bool = True):
    print("\n--- æ­¥é©Ÿ [vad]: VAD æ™ºèƒ½åˆ‡å‰² (ç§»é™¤éœéŸ³) ---")
    base_dir_to_use = DENOISED_SOURCES_BASE_DIR if use_denoised else RAW_SOURCES_BASE_DIR
    prompt_msg = f"è«‹è¼¸å…¥ä½æ–¼ '{base_dir_to_use}' ä¸‹çš„{'å·²é™å™ª' if use_denoised else 'åŸå§‹'}éŸ³è¨Šç³»åˆ—ç›®éŒ„åé€²è¡Œ VAD åˆ‡å‰²"

    if not input_series_dir_name:
        input_series_dir_name = get_user_input(prompt_msg, check_empty=True)

    audio_dir_to_segment = base_dir_to_use / input_series_dir_name
    if not audio_dir_to_segment.exists() or not audio_dir_to_segment.is_dir():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°éŸ³è¨Šç›®éŒ„ {audio_dir_to_segment} é€²è¡Œ VAD åˆ‡å‰²ã€‚")
        return None

    vad_output_dir = VAD_SEGMENTS_BASE_DIR / input_series_dir_name

    cmd = [
        PYTHON_EXECUTABLE, str(SCRIPTS_DIR / "vad_segmenter.py"),
        "--input_dir", str(audio_dir_to_segment),
        "--output_dir", str(vad_output_dir)
    ]
    success, _, _ = run_command(cmd)
    return vad_output_dir if success else None

def step_transcribe_audio(input_series_dir_name: str = None):
    print("\n--- æ­¥é©Ÿ [tr]: ä½¿ç”¨ Whisper è½‰éŒ„ (VADåˆ‡å‰²å¾Œçš„ç‰‡æ®µ) ---")
    base_dir_to_use = VAD_SEGMENTS_BASE_DIR
    prompt_msg = f"è«‹è¼¸å…¥ä½æ–¼ '{base_dir_to_use}' ä¸‹çš„ VAD å·²åˆ‡å‰²ç³»åˆ—ç›®éŒ„åé€²è¡Œè½‰éŒ„"

    if not input_series_dir_name:
        input_series_dir_name = get_user_input(prompt_msg, check_empty=True)

    audio_dir_to_transcribe = base_dir_to_use / input_series_dir_name
    if not audio_dir_to_transcribe.exists() or not audio_dir_to_transcribe.is_dir():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° VAD å·²åˆ‡å‰²çš„éŸ³è¨Šç›®éŒ„ {audio_dir_to_transcribe} é€²è¡Œè½‰éŒ„ã€‚")
        return None

    transcript_output_dir = RAW_TRANSCRIPTS_BASE_DIR / input_series_dir_name

    language = get_user_input("è«‹è¼¸å…¥éŸ³è¨Šèªè¨€ (ä¾‹å¦‚ ja, en, zh)", "ja")
    model_size = get_user_input("è«‹è¼¸å…¥ Whisper æ¨¡å‹å¤§å° (ä¾‹å¦‚ medium, large-v3)", "medium")

    cmd = [
        PYTHON_EXECUTABLE, str(SCRIPTS_DIR / "transcribe_audio.py"),
        "--input_dir", str(audio_dir_to_transcribe),
        "--output_dir", str(transcript_output_dir),
        "--language", language,
        "--model_size", model_size
    ]
    success, _, _ = run_command(cmd)
    return transcript_output_dir if success else None

def step_segment_audio_ffmpeg(transcript_metadata_path: Path = None,
                              audio_source_for_segmentation_dir_name: str = None,
                              use_denoised_for_segmentation: bool = True):
    print("\n--- æ­¥é©Ÿ [seg]: (èˆŠæµç¨‹) ä½¿ç”¨ FFmpeg æ ¹æ“šæ™‚é–“æˆ³åˆ†å‰²éŸ³è¨Š ---")
    print("è­¦å‘Šï¼šæ­¤æ­¥é©Ÿåœ¨æ–° VAD æµç¨‹ä¸­å·²è¢« [vad] æ­¥é©Ÿå–ä»£ï¼Œé€šå¸¸ç„¡éœ€åŸ·è¡Œã€‚")
    if not transcript_metadata_path:
        series_name_for_meta = get_user_input(f"è«‹è¼¸å…¥ä½æ–¼ '{RAW_TRANSCRIPTS_BASE_DIR}' ä¸‹çš„è½‰éŒ„ç³»åˆ—ç›®éŒ„åä»¥ç²å– metadata.csv", check_empty=True)
        transcript_metadata_path = RAW_TRANSCRIPTS_BASE_DIR / series_name_for_meta / "metadata.csv"

    if not transcript_metadata_path.exists():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è½‰éŒ„ metadata æª”æ¡ˆ {transcript_metadata_path}")
        return None

    audio_base_dir = DENOISED_SOURCES_BASE_DIR if use_denoised_for_segmentation else RAW_SOURCES_BASE_DIR
    if not audio_source_for_segmentation_dir_name:
        audio_source_for_segmentation_dir_name = get_user_input(
            f"è«‹è¼¸å…¥ä½æ–¼ '{audio_base_dir}' ä¸‹çš„{'å·²é™å™ª' if use_denoised_for_segmentation else 'åŸå§‹'}é•·éŸ³è¨Šç³»åˆ—ç›®éŒ„å (ç”¨æ–¼åˆ†å‰²)",
            default=transcript_metadata_path.parent.name
        )

    long_audio_parent_dir = audio_base_dir / audio_source_for_segmentation_dir_name
    if not long_audio_parent_dir.exists() or not long_audio_parent_dir.is_dir():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ç”¨æ–¼åˆ†å‰²çš„é•·éŸ³è¨Šç›®éŒ„ {long_audio_parent_dir}")
        return None

    temp_segments_output_dir = TEMP_SEGMENTS_BASE_DIR / audio_source_for_segmentation_dir_name

    segment_script_path = SCRIPTS_DIR / "segment_audio.py" # å‡è¨­èˆŠçš„åˆ†å‰²è…³æœ¬å
    if not segment_script_path.exists():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°èˆŠçš„åˆ†å‰²è…³æœ¬ {segment_script_path}ã€‚ç„¡æ³•åŸ·è¡Œæ­¤æ­¥é©Ÿã€‚")
        return None

    cmd = [
        PYTHON_EXECUTABLE, str(segment_script_path),
        "--metadata_path", str(transcript_metadata_path),
        "--raw_audio_parent_dir", str(long_audio_parent_dir),
        "--output_dir", str(temp_segments_output_dir)
    ]
    success, _, _ = run_command(cmd)
    return temp_segments_output_dir if success else None

def step_filter_denoise_segments(transcribed_series_dir_name: str = None, min_duration: float = 0.5):
    print("\n--- æ­¥é©Ÿ [flt]: éæ¿¾/æ•´ç†ç‰‡æ®µ (ä¸¦å¯é¸äºŒæ¬¡é™å™ª) ---")
    if not transcribed_series_dir_name:
        transcribed_series_dir_name = get_user_input(f"è«‹è¼¸å…¥ä½æ–¼ '{RAW_TRANSCRIPTS_BASE_DIR}' ä¸‹çš„å·²è½‰éŒ„ç³»åˆ—ç›®éŒ„å", check_empty=True)

    input_transcript_dir = RAW_TRANSCRIPTS_BASE_DIR / transcribed_series_dir_name
    input_audio_dir = VAD_SEGMENTS_BASE_DIR / transcribed_series_dir_name # éŸ³è¨Šç¾åœ¨ä¾†è‡ª VAD ç›®éŒ„

    if not input_transcript_dir.exists() or not (input_transcript_dir / "metadata.csv").exists():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è½‰éŒ„ç›®éŒ„ {input_transcript_dir} æˆ–å…¶ä¸‹çš„ metadata.csv")
        return None
    if not input_audio_dir.exists():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å°æ‡‰çš„ VAD éŸ³è¨Šç›®éŒ„ {input_audio_dir}")
        return None

    # denoise_audio_final.py çš„çŸ­ç‰‡æ®µæ¨¡å¼éœ€è¦éŸ³è¨Šå’Œ metadata.csv åœ¨åŒä¸€å€‹è¼¸å…¥ç›®éŒ„
    # æˆ‘å€‘å»ºç«‹ä¸€å€‹è‡¨æ™‚æ•´åˆç›®éŒ„ï¼Œä¸¦å°‡ VAD çš„éŸ³è¨Šèˆ‡ Whisper çš„ metadata è¤‡è£½é€²å»
    temp_filter_input_dir = TEMP_SEGMENTS_BASE_DIR / f"{transcribed_series_dir_name}_for_filtering"
    temp_filter_input_dir.mkdir(parents=True, exist_ok=True)

    print(f"æ­£åœ¨æº–å‚™éæ¿¾ï¼šå°‡éŸ³è¨Šèˆ‡ metadata è¤‡è£½åˆ°è‡¨æ™‚ç›®éŒ„ {temp_filter_input_dir}...")

    source_meta_path = input_transcript_dir / "metadata.csv"
    target_meta_path = temp_filter_input_dir / "metadata.csv"

    # è®€å– transcribe_audio.py ç”¢ç”Ÿçš„ metadata
    df = pd.read_csv(source_meta_path)
    # denoise_audio_final.py çš„çŸ­ç‰‡æ®µæ¨¡å¼æœŸæœ›çš„æª”åæ¬„ä½æ˜¯ 'segment_filename'
    # transcribe_audio.py ç”¢ç”Ÿçš„æª”åæ¬„ä½æ˜¯ 'filename'
    if 'filename' in df.columns:
        df.rename(columns={'filename': 'segment_filename'}, inplace=True)
    else:
        print(f"éŒ¯èª¤: {source_meta_path} ä¸­ç¼ºå°‘ 'filename' æ¬„ä½ã€‚")
        return None
    # ç¢ºä¿ 'text' æ¬„ä½å­˜åœ¨ï¼Œdenoise_audio_final.py ä¹Ÿæœƒç”¨åˆ°
    if 'text' not in df.columns:
        print(f"è­¦å‘Š: {source_meta_path} ä¸­ç¼ºå°‘ 'text' æ¬„ä½ï¼Œå°‡ç”¨ç©ºå­—ä¸²å¡«å……ã€‚")
        df['text'] = ""

    df.to_csv(target_meta_path, index=False, encoding='utf-8')
    print(f"Metadata å·²è¤‡è£½ä¸¦èª¿æ•´æ¬„ä½åè‡³ {target_meta_path}")

    # è¤‡è£½ VAD åˆ‡å‰²å¾Œçš„éŸ³è¨Šæª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„
    # ä½¿ç”¨ metadata ä¸­çš„æª”ååˆ—è¡¨ä¾†ç¢ºå®šè¦è¤‡è£½å“ªäº›æª”æ¡ˆ
    files_to_copy_from_metadata = df['segment_filename'].unique()
    copied_count = 0
    for audio_filename in tqdm(files_to_copy_from_metadata, desc="è¤‡è£½éŸ³è¨Šæª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„"):
        source_audio_file = input_audio_dir / audio_filename
        if source_audio_file.exists():
            shutil.copy(source_audio_file, temp_filter_input_dir / audio_filename)
            copied_count += 1
        else:
            print(f"è­¦å‘Šï¼šåœ¨ {source_meta_path} ä¸­åˆ—å‡ºçš„æª”æ¡ˆ {audio_filename} åœ¨ VAD éŸ³è¨Šç›®éŒ„ {input_audio_dir} ä¸­æœªæ‰¾åˆ°ï¼Œå·²è·³éã€‚")
    print(f"å·²è¤‡è£½ {copied_count} å€‹éŸ³è¨Šæª”æ¡ˆåˆ° {temp_filter_input_dir}")


    final_output_dir = FINAL_TRAINING_DATA_BASE_DIR / transcribed_series_dir_name

    cmd = [
        PYTHON_EXECUTABLE, str(SCRIPTS_DIR / "denoise_audio.py"), # å‡è¨­æ‚¨çš„é™å™ªè…³æœ¬åç‚º denoise_audio_final.py
        "--input_dir", str(temp_filter_input_dir),
        "--output_dir", str(final_output_dir),
        "--min_duration", str(min_duration)
        # batch_size ç­‰å…¶ä»–åƒæ•¸æœƒä½¿ç”¨ denoise_audio_final.py ä¸­çš„é è¨­å€¼
    ]
    success, _, _ = run_command(cmd)

    print(f"è‡¨æ™‚ç›®éŒ„ {temp_filter_input_dir} å·²ä¿ç•™ï¼Œæ–¹ä¾¿é™¤éŒ¯ã€‚å¯æ‰‹å‹•åˆªé™¤ã€‚")
    return final_output_dir if success else None

def step_train_tts_model(training_data_dir_name: str = None, config_file_path: Path = None, output_model_name_prefix: str = None):
    print("\n--- æ­¥é©Ÿ [train]: è¨“ç·´ TTS æ¨¡å‹ ---")
    if not training_data_dir_name:
        training_data_dir_name = get_user_input(f"è«‹è¼¸å…¥ä½æ–¼ '{FINAL_TRAINING_DATA_BASE_DIR}' ä¸‹çš„æœ€çµ‚è¨“ç·´è³‡æ–™ç³»åˆ—ç›®éŒ„å", check_empty=True)

    final_training_dir = FINAL_TRAINING_DATA_BASE_DIR / training_data_dir_name
    if not final_training_dir.exists() or not final_training_dir.is_dir() or not (final_training_dir / "metadata.csv").exists():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æœ€çµ‚è¨“ç·´è³‡æ–™ç›®éŒ„ {final_training_dir} æˆ–å…¶ä¸‹çš„ metadata.csv")
        return False

    if not config_file_path:
        config_file_path = get_user_input("è«‹è¼¸å…¥æ¨¡å‹è¨­å®šæª”è·¯å¾‘", default=str(DEFAULT_TRAIN_CONFIG_PATH), is_path=True, ensure_exists=True)
    if not config_file_path: return False

    if not output_model_name_prefix:
        output_model_name_prefix = get_user_input("è«‹ç‚ºè¼¸å‡ºçš„æ¨¡å‹æª”æ¡ˆè¨­å®šä¸€å€‹å‰ç¶´ (ä¾‹å¦‚ MyModelV1)", default=training_data_dir_name)

    output_model_path = DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR / f"{output_model_name_prefix}_tts_model.pth"

    # ã€ä¿®æ”¹ã€‘èª¿æ•´ ckpt_path çš„ç²å–æ–¹å¼ï¼Œå…è¨±ç›´æ¥æŒ‰ Enter è¡¨ç¤º None
    ckpt_prompt = "è‹¥è¦ç¹¼çºŒè¨“ç·´ï¼Œè«‹è¼¸å…¥æª¢æŸ¥é»æ¨¡å‹è·¯å¾‘ (.pth) (ç›´æ¥æŒ‰ Enter è¡¨ç¤ºä¸ä½¿ç”¨): "
    ckpt_path_str = input(ckpt_prompt).strip() # ç›´æ¥ä½¿ç”¨ inputï¼Œä¸¦å»é™¤å‰å¾Œç©ºæ ¼
    
    ckpt_path = None
    if ckpt_path_str: # åªæœ‰ç•¶ä½¿ç”¨è€…ç¢ºå¯¦è¼¸å…¥äº†å…§å®¹æ™‚æ‰å˜—è©¦è½‰æ›ç‚º Path
        ckpt_path = Path(ckpt_path_str)
        if not ckpt_path.exists():
            print(f"è­¦å‘Šï¼šæä¾›çš„æª¢æŸ¥é»è·¯å¾‘ '{ckpt_path_str}' ä¸å­˜åœ¨ï¼Œå°‡å¾é ­é–‹å§‹è¨“ç·´ã€‚")
            ckpt_path = None # è·¯å¾‘ç„¡æ•ˆï¼Œé‡ç½®ç‚º None
    else:
        print("ä¸ä½¿ç”¨æª¢æŸ¥é»ï¼Œå°‡å¾é ­é–‹å§‹è¨“ç·´æˆ–æ ¹æ“šå·²æœ‰æ¨¡å‹ï¼ˆå¦‚æœ output_model_path å·²å­˜åœ¨ï¼‰ç¹¼çºŒã€‚")

    train_script_module = "scripts.train_tts" # å‡è¨­æ‚¨çš„è¨“ç·´è…³æœ¬å¯ä»¥ä½œç‚ºæ¨¡çµ„åŸ·è¡Œ
    # æª¢æŸ¥è¨“ç·´è…³æœ¬æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœæ‚¨çš„è¨“ç·´è…³æœ¬ä¸æ˜¯ä»¥ -m æ–¹å¼åŸ·è¡Œçš„ï¼Œè«‹ç›¸æ‡‰ä¿®æ”¹
    # if not (SCRIPTS_DIR / "train_tts.py").exists():
    #     print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è¨“ç·´è…³æœ¬ {SCRIPTS_DIR / 'train_tts.py'}")
    #     return False

    cmd = [
        PYTHON_EXECUTABLE, "-m", train_script_module,
        "--config", str(config_file_path),
        "--data_dir", str(final_training_dir),
        "--output_model_path", str(output_model_path)
    ]
    if ckpt_path:
        cmd.extend(["--ckpt", str(ckpt_path)])

    success, _, _ = run_command(cmd)
    if success:
        print(f"ğŸ‰ è¨“ç·´å®Œæˆï¼æ¨¡å‹å·²å„²å­˜è‡³ (æˆ–æ›´æ–°æ–¼): {output_model_path}")
    return success

def step_synthesize_speech(model_path_str: str = None):
    print("\n--- æ­¥é©Ÿ [synth]: åˆæˆèªéŸ³ ---")
    if not model_path_str:
        model_path_str = get_user_input(f"è«‹è¼¸å…¥ TTS æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth) æˆ–ä½æ–¼ '{DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR}' ä¸‹çš„æ¨¡å‹å‰ç¶´å", check_empty=True)

    tts_model_path = Path(model_path_str)
    if not tts_model_path.is_file():
        potential_path = DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR / f"{model_path_str}_tts_model.pth"
        if potential_path.is_file():
            tts_model_path = potential_path
        else:
            potential_path_no_suffix = DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR / model_path_str
            if potential_path_no_suffix.is_file() and potential_path_no_suffix.suffix == ".pth":
                tts_model_path = potential_path_no_suffix
            else:
                print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° TTS æ¨¡å‹æª”æ¡ˆã€‚å˜—è©¦è·¯å¾‘: {model_path_str} å’Œ {potential_path}")
                return

    print(f"ä½¿ç”¨ TTS æ¨¡å‹: {tts_model_path}")
    output_dir = DEFAULT_SYNTHESIS_OUTPUT_BASE_DIR
    output_dir.mkdir(parents=True, exist_ok=True)
    input_type = get_user_input("è¼¸å…¥é¡å‹ (1: å–®ä¸€å¥å­, 2: æ–‡å­—æª”æ¡ˆ): ", "1")

    synth_script_module = "scripts.synthesize" # å‡è¨­æ‚¨çš„åˆæˆè…³æœ¬å¯ä»¥ä½œç‚ºæ¨¡çµ„åŸ·è¡Œ
    # if not (SCRIPTS_DIR / "synthesize.py").exists():
    #     print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åˆæˆè…³æœ¬ {SCRIPTS_DIR / 'synthesize.py'}")
    #     return

    cmd_synth_base = [
        PYTHON_EXECUTABLE, "-m", synth_script_module,
        "--model_path", str(tts_model_path)
    ]
    if input_type == "1":
        text_to_synth = get_user_input("è«‹è¼¸å…¥è¦åˆæˆçš„æ—¥æ–‡å¥å­", check_empty=True)
        output_filename = get_user_input("è«‹è¼¸å…¥è¼¸å‡º .wav æª”å (ä¸å«è·¯å¾‘)", default=f"synth_{Path(text_to_synth[:10].replace(' ','_')).stem}.wav")
        output_wav_path = output_dir / output_filename
        cmd_synth_base.extend(["--text", text_to_synth, "--output_path", str(output_wav_path)])
    elif input_type == "2":
        text_file_path = get_user_input("è«‹è¼¸å…¥æ–‡å­—æª”æ¡ˆè·¯å¾‘ (.txt)", is_path=True, ensure_exists=True, check_empty=True)
        output_filename = get_user_input("è«‹è¼¸å…¥åˆä½µè¼¸å‡ºçš„ .wav æª”å (ä¸å«è·¯å¾‘)", default=f"synth_batch_{text_file_path.stem}.wav")
        output_wav_path = output_dir / output_filename
        cmd_synth_base.extend(["--text_file", str(text_file_path), "--output_path", str(output_wav_path)])
    else:
        print("ç„¡æ•ˆçš„è¼¸å…¥é¡å‹ã€‚")
        return
    success, _, _ = run_command(cmd_synth_base)
    if success:
        print(f"ğŸ‰ åˆæˆçµæŸï¼æª”æ¡ˆä½æ–¼ {output_wav_path}")

def step_interactive_chat(model_path_str: str = None):
    print("\n--- æ­¥é©Ÿ [chat]: äº’å‹•å¼èŠå¤© ---")
    if not model_path_str:
        model_path_str = get_user_input(f"è«‹è¼¸å…¥ TTS æ¨¡å‹æª”æ¡ˆè·¯å¾‘ (.pth) æˆ–ä½æ–¼ '{DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR}' ä¸‹çš„æ¨¡å‹å‰ç¶´å", check_empty=True)
    tts_model_path = Path(model_path_str)
    if not tts_model_path.is_file():
        potential_path = DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR / f"{model_path_str}_tts_model.pth"
        if potential_path.is_file():
            tts_model_path = potential_path
        else:
            potential_path_no_suffix = DEFAULT_TTS_MODEL_OUTPUT_BASE_DIR / model_path_str
            if potential_path_no_suffix.is_file() and potential_path_no_suffix.suffix == ".pth":
                tts_model_path = potential_path_no_suffix
            else:
                print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° TTS æ¨¡å‹æª”æ¡ˆã€‚å˜—è©¦è·¯å¾‘: {model_path_str} å’Œ {potential_path}")
                return
    print(f"ä½¿ç”¨ TTS æ¨¡å‹: {tts_model_path}")
    llm_model_name = get_user_input("è«‹è¼¸å…¥ Ollama LLM æ¨¡å‹åç¨± (ä¾‹å¦‚ qwen:7b)", default="qwen:7b")

    chat_script_module = "scripts.chat" # å‡è¨­æ‚¨çš„èŠå¤©è…³æœ¬å¯ä»¥ä½œç‚ºæ¨¡çµ„åŸ·è¡Œ
    # if not (SCRIPTS_DIR / "chat.py").exists():
    #     print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°èŠå¤©è…³æœ¬ {SCRIPTS_DIR / 'chat.py'}")
    #     return

    cmd_chat = [
        PYTHON_EXECUTABLE, "-m", chat_script_module,
        "--model_path", str(tts_model_path),
        "--llm_model", llm_model_name
    ]
    print("æ­£åœ¨å•Ÿå‹•äº’å‹•å¼èŠå¤©...")
    print(f"æ‚¨å¯ä»¥æ‰‹å‹•åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼ˆå¦‚æœè‡ªå‹•å•Ÿå‹•å¤±æ•—ï¼‰ï¼š\n{' '.join(cmd_chat)}")
    try:
        run_command(cmd_chat)
    except KeyboardInterrupt:
        print("\näº’å‹•å¼èŠå¤©è¢«ä¸­æ–·ã€‚")
    except Exception as e:
        print(f"å•Ÿå‹•äº’å‹•å¼èŠå¤©æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def full_pipeline_execution():
    print("\n===== é–‹å§‹ã€æ–°ç‰ˆ VADã€‘å®Œæ•´è³‡æ–™æº–å‚™èˆ‡è¨“ç·´æµç¨‹ =====")
    print("æµç¨‹ï¼šä¸‹è¼‰ -> é™å™ªé•·éŸ³è¨Š -> VADæ™ºèƒ½åˆ‡å‰² -> Whisperè½‰éŒ„ -> éæ¿¾/æ•´ç†çŸ­ç‰‡æ®µ -> è¨“ç·´")
    print("-" * 30)

    # 1. ä¸‹è¼‰
    raw_audio_series_output_dir = step_download_audio()
    if not raw_audio_series_output_dir: return
    current_series_name = raw_audio_series_output_dir.name

    # 2. é™å™ªé•·éŸ³è¨Š
    denoised_long_audio_output_dir = step_denoise_long_audio(current_series_name)
    if not denoised_long_audio_output_dir: return

    # 3. VAD æ™ºèƒ½åˆ‡å‰² (ä½¿ç”¨é™å™ªå¾Œçš„éŸ³è¨Š)
    vad_segments_output_dir = step_vad_segmentation(current_series_name, use_denoised=True)
    if not vad_segments_output_dir: return

    # 4. Whisper è½‰éŒ„ (å° VAD åˆ‡å‰²å¾Œçš„ç‰‡æ®µ)
    transcribed_output_dir = step_transcribe_audio(current_series_name)
    if not transcribed_output_dir: return

    # 5. éæ¿¾/æ•´ç†çŸ­ç‰‡æ®µ
    min_duration_input = get_user_input("è«‹è¼¸å…¥éæ¿¾çŸ­ç‰‡æ®µçš„æœ€å°æ™‚é•· (ç§’)", "0.5")
    try:
        min_duration = float(min_duration_input)
    except ValueError:
        print(f"éŒ¯èª¤çš„æ™‚é•·è¼¸å…¥ '{min_duration_input}'ï¼Œå°‡ä½¿ç”¨é è¨­å€¼ 0.5 ç§’ã€‚")
        min_duration = 0.5
        
    final_training_data_output_dir = step_filter_denoise_segments(
        current_series_name,
        min_duration
    )
    if not final_training_data_output_dir: return

    # 6. è¨“ç·´
    step_train_tts_model(current_series_name, DEFAULT_TRAIN_CONFIG_PATH, current_series_name)
    print("===== å®Œæ•´ VAD æµç¨‹åŸ·è¡Œå®Œç•¢ =====")

def main():
    ensure_directories()
    global PYTHON_EXECUTABLE
    if VENV_PYTHON is None:
        # This was already printed at the top if VENV_PYTHON is None
        # print(f"è­¦å‘Šï¼šåœ¨é æœŸè·¯å¾‘ä¸­æ‰¾ä¸åˆ°è™›æ“¬ç’°å¢ƒçš„ Pythonã€‚å°‡å˜—è©¦ä½¿ç”¨ç³»çµ±é è¨­ 'python'ã€‚")
        # print(f"è«‹ç¢ºä¿ 'python' æŒ‡å‘æ‚¨å°ˆæ¡ˆçš„è™›æ“¬ç’°å¢ƒï¼Œå¦å‰‡å¯èƒ½ç™¼ç”Ÿå¥—ä»¶ç‰ˆæœ¬å•é¡Œã€‚")
        PYTHON_EXECUTABLE = "python"
    else:
        PYTHON_EXECUTABLE = str(VENV_PYTHON)
        # print(f"å°‡ä½¿ç”¨è™›æ“¬ç’°å¢ƒ Python: {PYTHON_EXECUTABLE}") # This was already printed at the top

    while True:
        print("\n\n======== TTS æ—¥èªèªéŸ³å°ˆæ¡ˆ CLI ä¸»æ§å° (VAD å¢å¼·ç‰ˆ) ========")
        print("æ¨è–¦æµç¨‹:")
        print("[1] ã€æ¨è–¦ã€‘å®Œæ•´ VAD æµç¨‹ï¼šä¸‹è¼‰ -> é™å™ª -> VADåˆ‡å‰² -> è½‰éŒ„ -> éæ¿¾ -> è¨“ç·´")
        print("-" * 40)
        print("å–®ç¨æ­¥é©Ÿ:")
        print("  [dl]  ä¸‹è¼‰ YouTube éŸ³è¨Š")
        print("  [dnl] é™å™ªé•·éŸ³è¨Š (éœ€å…ˆ [dl])")
        print("  [vad] VAD æ™ºèƒ½åˆ‡å‰² (éœ€å…ˆ [dl] æˆ– [dnl])")
        print("  [tr]  Whisper è½‰éŒ„ (éœ€å…ˆ [vad])")
        print("  [seg] (èˆŠæµç¨‹) FFmpeg åˆ†å‰² (å·²è¢« [vad] å–ä»£)")
        print("  [flt] éæ¿¾/æ•´ç†åˆ†å‰²ç‰‡æ®µ (éœ€å…ˆ [tr])")
        print("  [train] è¨“ç·´ TTS æ¨¡å‹ (éœ€å…ˆ [flt])")
        print("-" * 40)
        print("æ‡‰ç”¨åŠŸèƒ½:")
        print("  [synth] åˆæˆèªéŸ³")
        print("  [chat]  äº’å‹•å¼èŠå¤©")
        print("-" * 40)
        print("[0] é€€å‡º")

        choice = input("è«‹è¼¸å…¥é¸é …: ").lower().strip()

        if choice == '1':
            full_pipeline_execution()
        elif choice == 'dl':
            step_download_audio()
        elif choice == 'dnl':
            step_denoise_long_audio()
        elif choice == 'vad':
            use_denoised_q = get_user_input("æ˜¯å¦å°å·²é™å™ªçš„éŸ³è¨Šé€²è¡Œ VAD åˆ‡å‰²? (y/n)", "y").lower()
            step_vad_segmentation(use_denoised=(use_denoised_q == 'y'))
        elif choice == 'tr':
            step_transcribe_audio()
        elif choice == 'seg':
            print("è­¦å‘Šï¼šæ­¤ç‚ºèˆŠç‰ˆ FFmpeg åˆ†å‰²æµç¨‹ï¼Œåœ¨æ–°ç‰ˆ VAD æµç¨‹ä¸­é€šå¸¸ä¸éœ€è¦ã€‚")
            use_denoised_q = get_user_input("ç”¨æ–¼åˆ†å‰²çš„é•·éŸ³è¨Šæ˜¯å¦æ˜¯å·²é™å™ªç‰ˆæœ¬? (y/n)", "y").lower()
            step_segment_audio_ffmpeg(use_denoised_for_segmentation=(use_denoised_q == 'y'))
        elif choice == 'flt':
            step_filter_denoise_segments()
        elif choice == 'train':
            step_train_tts_model()
        elif choice == 'synth':
            step_synthesize_speech()
        elif choice == 'chat':
            step_interactive_chat()
        elif choice == '0':
            print("æ„Ÿè¬ä½¿ç”¨ï¼Œå†è¦‹ï¼")
            break
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")

if __name__ == "__main__":
    main()